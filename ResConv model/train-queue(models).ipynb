{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils import data\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\nfrom torch.optim import lr_scheduler\nfrom torch.optim import lr_scheduler\nimport time\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom torch.utils.data import random_split\n\nglobal cr\ncr = 0.96\n\n\ndef normalization(x: list):\n    M, m = np.max(x), np.min(x)\n    for i in range(len(x)):\n        x[i] = (x[i] - (M + m) / 2) / ((M - m) / 2)\n    # x in [-1, 1]\n    return M, m, x\n\ndef ArrNorm(x: np.ndarray):\n    assert isinstance(x, np.ndarray), \"We need a list\"\n    M_list, m_list, res = [], [], []\n    for i in range(x.shape[0]):\n        u = x[i].tolist()\n        M, m, t = normalization(u)\n        res.append(t)\n        M_list.append(M)\n        m_list.append(m)\n    return M_list, m_list, np.array(res)\n\n\ndef df2arr(x) -> np.ndarray:\n    return np.array(x, dtype=np.float32)\n\n\n\n# one train demo\n\nclass Try(nn.Module):\n    def __init__(self, seq, batch_size, scale=0):\n        super(Try, self).__init__()\n        self.scale = scale\n        self.seq = seq\n        self.batch_size = batch_size\n        self.linear = nn.Sequential(\n            nn.Linear((self.seq+1)*12, (self.seq+1)*6),\n            nn.Dropout(0.5),\n            nn.Sigmoid(),\n\n            nn.Linear((self.seq+1)*6, (self.seq+1)*6),\n            nn.Dropout(0.5),\n            nn.ReLU(inplace=True),\n\n        )\n        self.conv1 = nn.Sequential(\n            # seq * 5 \n            nn.Conv2d(1, 2, kernel_size=(3,3), padding=2, bias=False), # (seq+2) * 7\n            nn.BatchNorm2d(2),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(2, 2, kernel_size=(3,3), padding=1, bias=False), # (seq+2) * 7\n            nn.BatchNorm2d(2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=(2,2), stride=1), # (seq+1) * 6\n            \n        )\n        \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(1, 2, kernel_size=(2,2), padding=0, bias=False), # seq * 5\n            nn.BatchNorm2d(2),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(2, 1, kernel_size=(1,1), padding=0, bias=True), # seq * 5\n            nn.ReLU(inplace=True)\n\n        )\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = out.view(out.size()[0], -1)\n        out = self.linear(out)\n        # print(out.shape)\n        with torch.no_grad():\n            out = out.reshape(self.batch_size, 1, self.seq+1, 6)\n        out = self.conv2(out)\n        assert out.shape==x.shape, \"Shape Unequal Error.\"\n        return out + x\n    \n    \n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-20T16:48:54.289370Z","iopub.execute_input":"2023-03-20T16:48:54.289742Z","iopub.status.idle":"2023-03-20T16:48:54.312632Z","shell.execute_reply.started":"2023-03-20T16:48:54.289711Z","shell.execute_reply":"2023-03-20T16:48:54.311442Z"},"trusted":true},"execution_count":272,"outputs":[]},{"cell_type":"code","source":"import math\nimport numpy as np\nfrom scipy import stats\ndef rsquared(x, y): \n#     print(x.shape)\n    length = x.shape[-1]\n    assert x.shape==y.shape, \"Unequal Shape Error\"\n    r, x, y = [], x.detach(), y.detach()\n    x, y = x.mean(dim=[0,1], keepdim=False), y.mean(dim=[0,1], keepdim=False)\n#     print(x.shape)\n    for i in range(length):\n        _, _, r_value, _, _ = stats.linregress(x[:,i].detach().numpy(), y[:,i].detach().numpy()) \n        r.append(r_value ** 2)\n    return r","metadata":{"execution":{"iopub.status.busy":"2023-03-20T16:48:54.314980Z","iopub.execute_input":"2023-03-20T16:48:54.315458Z","iopub.status.idle":"2023-03-20T16:48:54.336412Z","shell.execute_reply.started":"2023-03-20T16:48:54.315418Z","shell.execute_reply":"2023-03-20T16:48:54.335220Z"},"trusted":true},"execution_count":273,"outputs":[]},{"cell_type":"code","source":"class NET(nn.Module):\n    def __init__(self, seq, batch_size, scale=0):\n        super(NET, self).__init__()\n        self.scale = scale\n        self.seq = seq\n        self.batch_size = batch_size\n        self.linear = nn.Sequential(\n            \n            nn.Linear((self.seq+1)*12, self.seq*5),\n            nn.Dropout(0.5),\n            nn.ReLU(inplace=True),\n            \n        )\n        self.conv1 = nn.Sequential(\n            # seq * 5 \n            nn.Conv2d(1, 2, kernel_size=(3,3), padding=2, bias=False), # (seq+2) * 7\n            nn.BatchNorm2d(2),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(2, 2, kernel_size=(3,3), padding=1, bias=False), # (seq+2) * 7\n            nn.BatchNorm2d(2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=(2,2), stride=1), # (seq+1) * 6\n            \n        )\n        \n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = out.view(out.size()[0], -1)\n        out = self.linear(out)\n        \n        with torch.no_grad():\n            out = out.reshape(self.batch_size, 1, self.seq, 5)\n#         print(out.shape, x.shape)\n        assert out.shape==x.shape, \"Shape Unequal Error.\"\n        return out + x\n    ","metadata":{"execution":{"iopub.status.busy":"2023-03-20T16:48:54.338207Z","iopub.execute_input":"2023-03-20T16:48:54.338680Z","iopub.status.idle":"2023-03-20T16:48:54.352303Z","shell.execute_reply.started":"2023-03-20T16:48:54.338639Z","shell.execute_reply":"2023-03-20T16:48:54.350791Z"},"trusted":true},"execution_count":274,"outputs":[]},{"cell_type":"code","source":"excel = pd.read_excel('/kaggle/input/a32-data/A32.xlsx', header=None)\nexcel.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-20T16:48:54.357751Z","iopub.execute_input":"2023-03-20T16:48:54.358130Z","iopub.status.idle":"2023-03-20T16:48:55.000382Z","shell.execute_reply.started":"2023-03-20T16:48:54.358075Z","shell.execute_reply":"2023-03-20T16:48:54.999259Z"},"trusted":true},"execution_count":275,"outputs":[{"execution_count":275,"output_type":"execute_result","data":{"text/plain":"(4459, 18)"},"metadata":{}}]},{"cell_type":"code","source":"sp = [1486, 2972, 4458]\nstation_1 = excel.iloc[1:sp[0]+1,1:6]\nstation_2 = excel.iloc[sp[0]+1:sp[1]+1,1:6]\nstandard = excel.iloc[sp[1]+1:sp[2]+1,1:6]\nstandard.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-20T16:48:55.001876Z","iopub.execute_input":"2023-03-20T16:48:55.003037Z","iopub.status.idle":"2023-03-20T16:48:55.012136Z","shell.execute_reply.started":"2023-03-20T16:48:55.002996Z","shell.execute_reply":"2023-03-20T16:48:55.011057Z"},"trusted":true},"execution_count":276,"outputs":[{"execution_count":276,"output_type":"execute_result","data":{"text/plain":"(1486, 5)"},"metadata":{}}]},{"cell_type":"code","source":"station_1 = df2arr(station_1)\nstation_2 = df2arr(station_2)\nstandard = df2arr(standard)\nstation_1.shape, station_2.shape, standard.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-20T16:48:55.013606Z","iopub.execute_input":"2023-03-20T16:48:55.014912Z","iopub.status.idle":"2023-03-20T16:48:55.026709Z","shell.execute_reply.started":"2023-03-20T16:48:55.014855Z","shell.execute_reply":"2023-03-20T16:48:55.025339Z"},"trusted":true},"execution_count":277,"outputs":[{"execution_count":277,"output_type":"execute_result","data":{"text/plain":"((1486, 5), (1486, 5), (1486, 5))"},"metadata":{}}]},{"cell_type":"code","source":"s1_minus_sd = station_1 - standard\ns2_minus_sd = station_2 - standard\ns1_div_sd = station_1 / standard\ns2_div_sd = station_2 / standard","metadata":{"execution":{"iopub.status.busy":"2023-03-20T16:48:55.029088Z","iopub.execute_input":"2023-03-20T16:48:55.029599Z","iopub.status.idle":"2023-03-20T16:48:55.035781Z","shell.execute_reply.started":"2023-03-20T16:48:55.029560Z","shell.execute_reply":"2023-03-20T16:48:55.034612Z"},"trusted":true},"execution_count":278,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in true_divide\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n  after removing the cwd from sys.path.\n","output_type":"stream"}]},{"cell_type":"code","source":"s1_minus_sd.shape, s2_minus_sd.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-20T16:48:55.037942Z","iopub.execute_input":"2023-03-20T16:48:55.038716Z","iopub.status.idle":"2023-03-20T16:48:55.047070Z","shell.execute_reply.started":"2023-03-20T16:48:55.038678Z","shell.execute_reply":"2023-03-20T16:48:55.045891Z"},"trusted":true},"execution_count":279,"outputs":[{"execution_count":279,"output_type":"execute_result","data":{"text/plain":"((1486, 5), (1486, 5))"},"metadata":{}}]},{"cell_type":"code","source":"s1_M, s1_m, s1 = ArrNorm(station_1)\ns2_M, s2_m, s2 = ArrNorm(station_2)","metadata":{"execution":{"iopub.status.busy":"2023-03-20T16:48:55.049115Z","iopub.execute_input":"2023-03-20T16:48:55.049609Z","iopub.status.idle":"2023-03-20T16:48:55.109526Z","shell.execute_reply.started":"2023-03-20T16:48:55.049546Z","shell.execute_reply":"2023-03-20T16:48:55.108452Z"},"trusted":true},"execution_count":280,"outputs":[]},{"cell_type":"code","source":"def GetDataset(input_arr: list, output_arr: list, seq: int):\n    assert(len(input_arr)==len(output_arr)), \"Different size of input and output!\"\n    Input = []\n    Output = []\n    for i in range(input_arr.shape[0]-seq):\n        Input.append(input_arr[i:i+seq][:])\n        Output.append(output_arr[i:i+seq][:])\n    return torch.tensor(Input, dtype=torch.float32), torch.tensor(Output, dtype=torch.float32)\n\n        \ndef load_array(data_arrays, batch_size, is_train=True):\n    # data-iter\n    dataset = data.TensorDataset(*data_arrays)\n    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n\ns1_minus_sd.shape","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-03-20T16:48:55.113242Z","iopub.execute_input":"2023-03-20T16:48:55.113661Z","iopub.status.idle":"2023-03-20T16:48:55.124117Z","shell.execute_reply.started":"2023-03-20T16:48:55.113624Z","shell.execute_reply":"2023-03-20T16:48:55.122845Z"},"trusted":true},"execution_count":281,"outputs":[{"execution_count":281,"output_type":"execute_result","data":{"text/plain":"(1486, 5)"},"metadata":{}}]},{"cell_type":"code","source":"# global sequence, batch_size\n# batch_size = 4\n# sequence = 6\n\n# global lr, num_epoch\n# lr, num_epoch = 0.000001, 100\n# status_list = ['MINUS', 'DIVIDE']\nstatus_list = [\"MINUS\"]\nname_list = [\"TRY\", \"NET\"]\nglobal record\nrecord_R = []\nrecord_con = []\n\ndef train(name, status, batch_size, sequence, lr, num_epoch, ga):\n    string = name+\":\"+\"&\"+str(status)+\"&batch_size=\"+str(batch_size)+\"&sequence=\"+str(sequence)+\"&\"\n    \n    Input_Data_1, Output_Data_1 = GetDataset(s1, s1_minus_sd, sequence) if status==\"MINUS\" else GetDataset(s1,s1_div_sd, sequence)\n    Input_Data_2, Output_Data_2 = GetDataset(s2, s2_minus_sd, sequence) if status==\"MINUS\" else GetDataset(s2,s2_div_sd, sequence)\n    Input_Data_1.shape, Input_Data_2.shape\n\n    Input_Data_1 = Input_Data_1.unsqueeze(1)\n    Output_Data_1 = Output_Data_1.unsqueeze(1)\n    Input_Data_2 = Input_Data_2.unsqueeze(1)\n    Output_Data_2 = Output_Data_2.unsqueeze(1)\n    Input_Data_1.shape, Input_Data_1.shape\n\n\n    data_tot_1 = torch.utils.data.TensorDataset(Input_Data_1, Output_Data_1)\n    data_tot_2 = torch.utils.data.TensorDataset(Input_Data_2, Output_Data_2)\n    train_size = int(Input_Data_1.shape[0] * cr)\n    test_size = Input_Data_1.shape[0] - train_size\n    train_set_1, test_set_1 = random_split(data_tot_1,[train_size,test_size],\n                                        torch.Generator().manual_seed(0))\n    train_set_2, test_set_2 = random_split(data_tot_2,[train_size,test_size],\n                                        torch.Generator().manual_seed(0))\n    # DataIter = load_array((Input_Data_1, Output_Data_1), batch_size=8)\n\n\n\n\n    Data_Iter_1 = DataLoader(dataset=train_set_1, batch_size=batch_size, shuffle=True, drop_last=True)\n    Data_Iter_2 = DataLoader(dataset=train_set_2, batch_size=batch_size, shuffle=True, drop_last=True)\n\n    for i, dt in enumerate(Data_Iter_1):\n        if dt[0].shape[0]!=batch_size:\n            print(dt[0].shape)\n            print(i, batch_size, dt[0].shape[0], dt)\n\n    for i, dt in enumerate(Data_Iter_2):\n        if dt[0].shape[0]!=batch_size:\n            print(dt[0].shape)\n            print(i, batch_size, dt[0].shape[0], dt)\n\n    x_plt, train_loss_plt = [], []\n\n\n    net = Try(batch_size=batch_size, seq=sequence).cuda() if name==\"TRY\" else NET(batch_size=batch_size, seq=sequence).cuda()\n    Loss = torch.nn.MSELoss()\n    optimizer = torch.optim.Adam(net.parameters(), lr)\n    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=ga)\n\n    def Iter(num_epoch):\n        cnt = 0\n        while cnt < num_epoch:\n            yield cnt\n            cnt += 1\n\n    print(\"\\nStart Training with condition: \"+string)\n    print(\"Round 1...\")\n    for epoch in range(num_epoch):\n        epoch_start_time = time.time()\n        train_loss = 0.0\n        net.train()\n        for i, use in enumerate(tqdm(Data_Iter_1)):\n            optimizer.zero_grad()\n            # if use[0].shape[0]==2:\n            #     print(use[0])\n            train_pred = net(use[0].cuda())    # use[0].cuda()\n\n            batch_loss = Loss(train_pred, use[1].cuda())   # use[1].cuda()\n            batch_loss.backward()\n            optimizer.step()\n#             R2 = R_square(train_pred.cpu(), use[1].cpu())\n\n            train_loss += batch_loss.item()\n\n        train_loss = train_loss / train_size\n        x_plt.append(epoch+1)\n        train_loss_plt.append(train_loss)\n        print(\"Round-1 --- [%2d|%2d] %.2f(s) Train_Loss=%.6f \"%\\\n                (epoch+1,num_epoch,time.time()-epoch_start_time,train_loss),end='')\n    #   epoch_start_time = time.time()\n        scheduler.step()  \n\n    plt.figure(1)\n    plt.plot(x_plt,train_loss_plt,'rs-',label='all_train_loss')\n    plt.show()\n\n    print(\"Round 2...\")\n    for epoch in range(num_epoch):\n        epoch_start_time = time.time()\n        train_loss = 0.0\n        net.train()\n        for i, use in enumerate(tqdm(Data_Iter_2)):\n            optimizer.zero_grad()\n            # if use[0].shape[0]==2:\n            #     print(use[0])\n            train_pred = net(use[0].cuda())    # use[0].cuda()\n\n            batch_loss = Loss(train_pred, use[1].cuda())   # use[1].cuda()\n            batch_loss.backward()\n            optimizer.step()\n            # R2 = rsquared(train_pred.cpu(), use[1].cpu())\n\n            train_loss += batch_loss.item()\n\n        train_loss = train_loss / train_size\n        x_plt.append(epoch+num_epoch+1)\n        train_loss_plt.append(train_loss)\n        print(\"Round 2 --- [%2d|%2d] %.2f(s) Train_Loss=%.6f \"%\\\n                (epoch+1,num_epoch,time.time()-epoch_start_time,train_loss),end='')\n    #   epoch_start_time = time.time()\n        scheduler.step() \n\n\n    plt.figure(2)\n    plt.plot(x_plt,train_loss_plt,'rs-',label='all_train_loss')\n    plt.show()\n\n    torch.save(net.state_dict(), '/kaggle/working/'+string+\".pt\")\n    print(\"Parameters Saved.\")\n\n\n    Test_Iter_1 = DataLoader(dataset=test_set_1, batch_size=1, shuffle=False, drop_last=True)\n    model = Try(batch_size=1, seq=sequence) if name==\"TRY\" else NET(batch_size=1,seq=sequence)\n    model.load_state_dict(torch.load('/kaggle/working/'+string+\".pt\"))\n    model = model.cuda()\n    model.eval()\n    R_list = [[],[],[],[],[]]\n    def app(R: list)-> list:\n        assert len(R)==5\n        for i in range(len(R_list)):\n            R_list[i].append(R[i])\n\n    with torch.no_grad():\n        for i, use in enumerate(Test_Iter_1):\n            pred = model(use[0].cuda())\n            R = rsquared(pred.cpu(), use[1])\n            print(i, R)\n            for i in range(5):\n                R_list[0].append(R)\n                           \n                           \n    Test_Iter_2 = DataLoader(dataset=test_set_2, batch_size=1, shuffle=False, drop_last=True)\n\n    with torch.no_grad():\n        for i, use in enumerate(Test_Iter_2):\n            pred = model(use[0].cuda())\n    #         print(pred.shape, use[1].shape)\n            R = rsquared(pred.cpu(), use[1])\n            print(i, R)\n            for i in range(5):\n                R_list[0].append(R)\n    \n    record_R.append(R_list)\n    record_con.append(string)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-20T16:48:55.126499Z","iopub.execute_input":"2023-03-20T16:48:55.126977Z","iopub.status.idle":"2023-03-20T16:48:55.162841Z","shell.execute_reply.started":"2023-03-20T16:48:55.126938Z","shell.execute_reply":"2023-03-20T16:48:55.161679Z"},"trusted":true},"execution_count":282,"outputs":[]},{"cell_type":"code","source":"# train(\"NET\",'MINUS',2,6,0.0001,5,0.9)","metadata":{"execution":{"iopub.status.busy":"2023-03-20T16:48:55.164521Z","iopub.execute_input":"2023-03-20T16:48:55.165108Z","iopub.status.idle":"2023-03-20T16:48:55.170165Z","shell.execute_reply.started":"2023-03-20T16:48:55.165070Z","shell.execute_reply":"2023-03-20T16:48:55.168826Z"},"trusted":true},"execution_count":283,"outputs":[]},{"cell_type":"code","source":"# record_R, record_con","metadata":{"execution":{"iopub.status.busy":"2023-03-20T16:48:55.171738Z","iopub.execute_input":"2023-03-20T16:48:55.172198Z","iopub.status.idle":"2023-03-20T16:48:55.181882Z","shell.execute_reply.started":"2023-03-20T16:48:55.172159Z","shell.execute_reply":"2023-03-20T16:48:55.181147Z"},"trusted":true},"execution_count":284,"outputs":[]},{"cell_type":"code","source":"status = \"MINUS\"\nnum_epoch = 1200\nga = 0.90\nlr = 0.0001\n\nfor batch_size in [2,4,8,16,32,64]:\n    for sequence in [4,5,6,7,8,9,10]:\n        for name in name_list:\n            train(name, status, batch_size, sequence, lr, num_epoch, ga)","metadata":{"execution":{"iopub.status.busy":"2023-03-20T16:48:55.183743Z","iopub.execute_input":"2023-03-20T16:48:55.184781Z","iopub.status.idle":"2023-03-20T16:49:01.689587Z","shell.execute_reply.started":"2023-03-20T16:48:55.184740Z","shell.execute_reply":"2023-03-20T16:49:01.687851Z"},"trusted":true},"execution_count":285,"outputs":[{"name":"stdout","text":"\nStart Training with condition: TRY:&MINUS&batch_size=2&sequence=4&\nRound 1...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 711/711 [00:01<00:00, 376.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Round-1 --- [ 1|1200] 1.89(s) Train_Loss=111.052097 ","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 711/711 [00:01<00:00, 384.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Round-1 --- [ 2|1200] 1.85(s) Train_Loss=111.052097 ","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 711/711 [00:01<00:00, 366.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Round-1 --- [ 3|1200] 1.95(s) Train_Loss=111.052097 ","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 169/711 [00:00<00:02, 261.34it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/624777831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mga\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_24/1524127359.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(name, status, batch_size, sequence, lr, num_epoch, ga)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m# if use[0].shape[0]==2:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m#     print(use[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# use[0].cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# use[1].cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_24/4262365235.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}
{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils import data\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\nfrom torch.optim import lr_scheduler\nfrom torch.optim import lr_scheduler\nimport time\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom torch.utils.data import random_split\n\nglobal cr\ncr = 0.96\n\n\ndef normalization(x: list):\n    M, m = np.max(x), np.min(x)\n    for i in range(len(x)):\n        x[i] = (x[i] - (M + m) / 2) / ((M - m) / 2)\n    # x in [-1, 1]\n    return M, m, x\n\ndef ArrNorm(x: np.ndarray):\n    assert isinstance(x, np.ndarray), \"We need a list\"\n    M_list, m_list, res = [], [], []\n    for i in range(x.shape[0]):\n        u = x[i].tolist()\n        M, m, t = normalization(u)\n        res.append(t)\n        M_list.append(M)\n        m_list.append(m)\n    return M_list, m_list, np.array(res)\n\n\ndef df2arr(x) -> np.ndarray:\n    return np.array(x, dtype=np.float32)\n\n\n\n# one train demo\n\nclass Try(nn.Module):\n    def __init__(self, seq, batch_size, scale=0):\n        super(Try, self).__init__()\n        self.scale = scale\n        self.seq = seq\n        self.batch_size = batch_size\n        self.linear = nn.Sequential(\n            nn.Linear((self.seq+1)*12, (self.seq+1)*6),\n            nn.Dropout(0.5),\n            nn.Sigmoid(),\n\n            nn.Linear((self.seq+1)*6, (self.seq+1)*6),\n            nn.Dropout(0.5),\n            nn.ReLU(inplace=True),\n\n        )\n        self.conv1 = nn.Sequential(\n            # seq * 5 \n            nn.Conv2d(1, 2, kernel_size=(3,3), padding=2, bias=False), # (seq+2) * 7\n            nn.BatchNorm2d(2),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(2, 2, kernel_size=(3,3), padding=1, bias=False), # (seq+2) * 7\n            nn.BatchNorm2d(2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=(2,2), stride=1), # (seq+1) * 6\n            \n        )\n        \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(1, 30, kernel_size=(2,2), padding=0, bias=False), # seq * 5\n            nn.BatchNorm2d(30),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(30, 1, kernel_size=(1,1), padding=0, bias=True), # seq * 5\n            nn.ReLU(inplace=True)\n\n        )\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = out.view(out.size()[0], -1)\n        out = self.linear(out)\n        # print(out.shape)\n        with torch.no_grad():\n            out = out.reshape(self.batch_size, 1, self.seq+1, 6)\n        out = self.conv2(out)\n        assert out.shape==x.shape, \"Shape Unequal Error.\"\n        return out + x\n    \n    \n\nimport math\nimport numpy as np\nfrom scipy import stats\ndef rsquared(x, y): \n    assert x.shape==y.shape, \"Unequal Shape Error\"\n    r, x, y = [], x.detach(), y.detach()\n    x, y = x.mean(dim=[0,1], keepdim=False), y.mean(dim=[0,1], keepdim=False)\n    for i in range(x.shape[-1]):\n        _, _, r_value, _, _ = stats.linregress(x[:][i].detach().numpy(), y[:][i].detach().numpy()) \n        r.append(r_value ** 2)\n    return r\n","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:16:49.093707Z","iopub.execute_input":"2023-03-19T17:16:49.094295Z","iopub.status.idle":"2023-03-19T17:16:49.120343Z","shell.execute_reply.started":"2023-03-19T17:16:49.094248Z","shell.execute_reply":"2023-03-19T17:16:49.119030Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"excel = pd.read_excel('/kaggle/input/a32-data/A32.xlsx', header=None)\nexcel.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:16:49.123150Z","iopub.execute_input":"2023-03-19T17:16:49.123937Z","iopub.status.idle":"2023-03-19T17:16:49.771165Z","shell.execute_reply.started":"2023-03-19T17:16:49.123893Z","shell.execute_reply":"2023-03-19T17:16:49.770173Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"(4459, 18)"},"metadata":{}}]},{"cell_type":"code","source":"sp = [1486, 2972, 4458]\nstation_1 = excel.iloc[1:sp[0]+1,1:6]\nstation_2 = excel.iloc[sp[0]+1:sp[1]+1,1:6]\nstandard = excel.iloc[sp[1]+1:sp[2]+1,1:6]\nstandard.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:16:49.772920Z","iopub.execute_input":"2023-03-19T17:16:49.773279Z","iopub.status.idle":"2023-03-19T17:16:49.782028Z","shell.execute_reply.started":"2023-03-19T17:16:49.773241Z","shell.execute_reply":"2023-03-19T17:16:49.780917Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"(1486, 5)"},"metadata":{}}]},{"cell_type":"code","source":"station_1 = df2arr(station_1)\nstation_2 = df2arr(station_2)\nstandard = df2arr(standard)\nstation_1.shape, station_2.shape, standard.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:16:49.785367Z","iopub.execute_input":"2023-03-19T17:16:49.786103Z","iopub.status.idle":"2023-03-19T17:16:49.795888Z","shell.execute_reply.started":"2023-03-19T17:16:49.786062Z","shell.execute_reply":"2023-03-19T17:16:49.794614Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"((1486, 5), (1486, 5), (1486, 5))"},"metadata":{}}]},{"cell_type":"code","source":"s1_minus_sd = station_1 - standard\ns2_minus_sd = station_2 - standard\ns1_div_sd = station_1 / standard\ns2_div_sd = station_2 / standard","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:16:49.797660Z","iopub.execute_input":"2023-03-19T17:16:49.798092Z","iopub.status.idle":"2023-03-19T17:16:49.805956Z","shell.execute_reply.started":"2023-03-19T17:16:49.798054Z","shell.execute_reply":"2023-03-19T17:16:49.804419Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in true_divide\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n  after removing the cwd from sys.path.\n","output_type":"stream"}]},{"cell_type":"code","source":"s1_minus_sd.shape, s2_minus_sd.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:16:49.807829Z","iopub.execute_input":"2023-03-19T17:16:49.809176Z","iopub.status.idle":"2023-03-19T17:16:49.820806Z","shell.execute_reply.started":"2023-03-19T17:16:49.809144Z","shell.execute_reply":"2023-03-19T17:16:49.819322Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"((1486, 5), (1486, 5))"},"metadata":{}}]},{"cell_type":"code","source":"s1_M, s1_m, s1 = ArrNorm(station_1)\ns2_M, s2_m, s2 = ArrNorm(station_2)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:16:49.822805Z","iopub.execute_input":"2023-03-19T17:16:49.823548Z","iopub.status.idle":"2023-03-19T17:16:49.890176Z","shell.execute_reply.started":"2023-03-19T17:16:49.823506Z","shell.execute_reply":"2023-03-19T17:16:49.889084Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def GetDataset(input_arr: list, output_arr: list, seq: int):\n    assert(len(input_arr)==len(output_arr)), \"Different size of input and output!\"\n    Input = []\n    Output = []\n    for i in range(input_arr.shape[0]-seq):\n        Input.append(input_arr[i:i+seq][:])\n        Output.append(output_arr[i:i+seq][:])\n    return torch.tensor(Input, dtype=torch.float32), torch.tensor(Output, dtype=torch.float32)\n\n        \ndef load_array(data_arrays, batch_size, is_train=True):\n    # data-iter\n    dataset = data.TensorDataset(*data_arrays)\n    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n\ns1_minus_sd.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:16:49.891856Z","iopub.execute_input":"2023-03-19T17:16:49.892538Z","iopub.status.idle":"2023-03-19T17:16:49.904153Z","shell.execute_reply.started":"2023-03-19T17:16:49.892497Z","shell.execute_reply":"2023-03-19T17:16:49.902889Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"(1486, 5)"},"metadata":{}}]},{"cell_type":"code","source":"# global sequence, batch_size\n# batch_size = 4\n# sequence = 6\n\n# global lr, num_epoch\n# lr, num_epoch = 0.000001, 100\n# status_list = ['MINUS', 'DIVIDE']\nstatus_list = [\"MINUS\"]\nglobal record\nrecord_R = []\nrecord_con = []\n\ndef train(status, batch_size, sequence, lr, num_epoch, ga):\n    string = \"&\"+str(status)+\"&batch_size=\"+str(batch_size)+\"&sequence=\"+str(sequence)+\"&lr=\"+str(lr)+\"&num_epoch\"+str(num_epoch)+\"&gama=\"+str(ga)+\"&\"\n    \n    Input_Data_1, Output_Data_1 = GetDataset(s1, s1_minus_sd, sequence) if status==\"MINUS\" else GetDataset(s1,s1_div_sd, sequence)\n    Input_Data_2, Output_Data_2 = GetDataset(s2, s2_minus_sd, sequence) if status==\"MINUS\" else GetDataset(s2,s2_div_sd, sequence)\n    Input_Data_1.shape, Input_Data_2.shape\n\n    Input_Data_1 = Input_Data_1.unsqueeze(1)\n    Output_Data_1 = Output_Data_1.unsqueeze(1)\n    Input_Data_2 = Input_Data_2.unsqueeze(1)\n    Output_Data_2 = Output_Data_2.unsqueeze(1)\n    Input_Data_1.shape, Input_Data_1.shape\n\n\n    data_tot_1 = torch.utils.data.TensorDataset(Input_Data_1, Output_Data_1)\n    data_tot_2 = torch.utils.data.TensorDataset(Input_Data_2, Output_Data_2)\n    train_size = int(Input_Data_1.shape[0] * cr)\n    test_size = Input_Data_1.shape[0] - train_size\n    train_set_1, test_set_1 = random_split(data_tot_1,[train_size,test_size],\n                                        torch.Generator().manual_seed(0))\n    train_set_2, test_set_2 = random_split(data_tot_2,[train_size,test_size],\n                                        torch.Generator().manual_seed(0))\n    # DataIter = load_array((Input_Data_1, Output_Data_1), batch_size=8)\n\n\n\n\n    Data_Iter_1 = DataLoader(dataset=train_set_1, batch_size=batch_size, shuffle=True, drop_last=True)\n    Data_Iter_2 = DataLoader(dataset=train_set_2, batch_size=batch_size, shuffle=True, drop_last=True)\n\n    for i, dt in enumerate(Data_Iter_1):\n        if dt[0].shape[0]!=batch_size:\n            print(dt[0].shape)\n            print(i, batch_size, dt[0].shape[0], dt)\n\n    for i, dt in enumerate(Data_Iter_2):\n        if dt[0].shape[0]!=batch_size:\n            print(dt[0].shape)\n            print(i, batch_size, dt[0].shape[0], dt)\n\n    x_plt, train_loss_plt = [], []\n\n\n    net = Try(batch_size=batch_size, seq=sequence).cuda()\n    Loss = torch.nn.MSELoss()\n    optimizer = torch.optim.Adam(net.parameters(), lr)\n    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=ga)\n\n    def Iter(num_epoch):\n        cnt = 0\n        while cnt < num_epoch:\n            yield cnt\n            cnt += 1\n\n    print(\"\\nStart Training with condition: \"+string)\n    print(\"Round 1...\")\n    for epoch in range(num_epoch):\n        epoch_start_time = time.time()\n        train_loss = 0.0\n        net.train()\n        for i, use in enumerate(tqdm(Data_Iter_1)):\n            optimizer.zero_grad()\n            # if use[0].shape[0]==2:\n            #     print(use[0])\n            train_pred = net(use[0].cuda())    # use[0].cuda()\n\n            batch_loss = Loss(train_pred, use[1].cuda())   # use[1].cuda()\n            batch_loss.backward()\n            optimizer.step()\n#             R2 = R_square(train_pred.cpu(), use[1].cpu())\n\n            train_loss += batch_loss.item()\n\n        train_loss = train_loss / train_size\n        x_plt.append(epoch+1)\n        train_loss_plt.append(train_loss)\n        print(\"Round-1 --- [%2d|%2d] %.2f(s) Train_Loss=%.6f \"%\\\n                (epoch+1,num_epoch,time.time()-epoch_start_time,train_loss),end='')\n    #   epoch_start_time = time.time()\n        scheduler.step()  \n\n    plt.figure(1)\n    plt.plot(x_plt,train_loss_plt,'rs-',label='all_train_loss')\n    plt.show()\n\n    print(\"Round 2...\")\n    for epoch in range(num_epoch):\n        epoch_start_time = time.time()\n        train_loss = 0.0\n        net.train()\n        for i, use in enumerate(tqdm(Data_Iter_2)):\n            optimizer.zero_grad()\n            # if use[0].shape[0]==2:\n            #     print(use[0])\n            train_pred = net(use[0].cuda())    # use[0].cuda()\n\n            batch_loss = Loss(train_pred, use[1].cuda())   # use[1].cuda()\n            batch_loss.backward()\n            optimizer.step()\n            # R2 = rsquared(train_pred.cpu(), use[1].cpu())\n\n            train_loss += batch_loss.item()\n\n        train_loss = train_loss / train_size\n        x_plt.append(epoch+num_epoch+1)\n        train_loss_plt.append(train_loss)\n        print(\"Round 2 --- [%2d|%2d] %.2f(s) Train_Loss=%.6f \"%\\\n                (epoch+1,num_epoch,time.time()-epoch_start_time,train_loss),end='')\n    #   epoch_start_time = time.time()\n        scheduler.step() \n\n\n    plt.figure(2)\n    plt.plot(x_plt,train_loss_plt,'rs-',label='all_train_loss')\n    plt.show()\n\n    torch.save(net.state_dict(), '/kaggle/working/'+string+\".pt\")\n    print(\"Parameters Saved.\")\n\n\n    Test_Iter_1 = DataLoader(dataset=test_set_1, batch_size=1, shuffle=False, drop_last=True)\n    model = Try(batch_size=1, seq=sequence)\n    model.load_state_dict(torch.load('/kaggle/working/'+string+\".pt\"))\n    model = model.cuda()\n    model.eval()\n    R_list = [[],[],[],[],[]]\n    def app(R: list)-> list:\n        assert len(R)==5\n        for i in range(len(R_list)):\n            R_list[i].append(R[i])\n\n    with torch.no_grad():\n        for i, use in enumerate(Test_Iter_1):\n            pred = model(use[0].cuda())\n            R = rsquared(pred.cpu(), use[1])\n            print(i, R)\n            for i in range(5):\n                R_list[0].append(R)\n                           \n                           \n    Test_Iter_2 = DataLoader(dataset=test_set_2, batch_size=1, shuffle=False, drop_last=True)\n\n    with torch.no_grad():\n        for i, use in enumerate(Test_Iter_2):\n            pred = model(use[0].cuda())\n    #         print(pred.shape, use[1].shape)\n            R = rsquared(pred.cpu(), use[1])\n            print(i, R)\n            for i in range(5):\n                R_list[0].append(R)\n    \n    record_R.append(R_list)\n    record_con.append(string)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:16:49.906219Z","iopub.execute_input":"2023-03-19T17:16:49.906645Z","iopub.status.idle":"2023-03-19T17:16:49.936072Z","shell.execute_reply.started":"2023-03-19T17:16:49.906607Z","shell.execute_reply":"2023-03-19T17:16:49.934913Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# train('MINUS',10,6,0.0001,5,0.9)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:16:49.941436Z","iopub.execute_input":"2023-03-19T17:16:49.942992Z","iopub.status.idle":"2023-03-19T17:16:49.948133Z","shell.execute_reply.started":"2023-03-19T17:16:49.942912Z","shell.execute_reply":"2023-03-19T17:16:49.946888Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# record_R, record_con","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:16:49.949991Z","iopub.execute_input":"2023-03-19T17:16:49.950477Z","iopub.status.idle":"2023-03-19T17:16:49.957172Z","shell.execute_reply.started":"2023-03-19T17:16:49.950438Z","shell.execute_reply":"2023-03-19T17:16:49.955639Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"for status in status_list:\n    for num_epoch in [500,1000,1500]:\n        for ga in [0.80,0.85,0.90]:\n            for batch_size in [2,4,8,16,32,64]:\n                for lr in [0.00001,0.0001,0.0001,0.001,0.03]:\n                    for sequence in [4,5,6,7,8,9,10]:\n                        train(status, batch_size, sequence, lr, num_epoch, ga)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:16:49.958734Z","iopub.execute_input":"2023-03-19T17:16:49.959577Z","iopub.status.idle":"2023-03-19T17:16:53.374440Z","shell.execute_reply.started":"2023-03-19T17:16:49.959534Z","shell.execute_reply":"2023-03-19T17:16:53.372929Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"\nStart Training with condition: &MINUS&batch_size=2&sequence=4&lr=1e-05&num_epoch500&gama=0.8&\nRound 1...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 711/711 [00:01<00:00, 381.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Round-1 --- [ 1|500] 1.87(s) Train_Loss=111.250899 ","output_type":"stream"},{"name":"stderr","text":" 75%|███████▍  | 531/711 [00:01<00:00, 380.45it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1372506031.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.03\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mga\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_23/1948335442.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(status, batch_size, sequence, lr, num_epoch, ga)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# use[1].cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m#             R2 = R_square(train_pred.cpu(), use[1].cpu())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         )\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}
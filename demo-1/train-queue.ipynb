{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils import data\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\nfrom torch.optim import lr_scheduler\nfrom torch.optim import lr_scheduler\nimport time\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom torch.utils.data import random_split\n\nglobal cr\ncr = 0.96\n\n\ndef normalization(x: list):\n    M, m = np.max(x), np.min(x)\n    for i in range(len(x)):\n        x[i] = (x[i] - (M + m) / 2) / ((M - m) / 2)\n    # x in [-1, 1]\n    return M, m, x\n\ndef ArrNorm(x: np.ndarray):\n    assert isinstance(x, np.ndarray), \"We need a list\"\n    M_list, m_list, res = [], [], []\n    for i in range(x.shape[0]):\n        u = x[i].tolist()\n        M, m, t = normalization(u)\n        res.append(t)\n        M_list.append(M)\n        m_list.append(m)\n    return M_list, m_list, np.array(res)\n\n\ndef df2arr(x) -> np.ndarray:\n    return np.array(x, dtype=np.float32)\n\n\n\n# one train demo\n\nclass Try(nn.Module):\n    def __init__(self, seq, batch_size, scale=0):\n        super(Try, self).__init__()\n        self.scale = scale\n        self.seq = seq\n        self.batch_size = batch_size\n        self.linear = nn.Sequential(\n            nn.Linear((self.seq+1)*12, (self.seq+1)*6),\n            nn.Dropout(0.5),\n            nn.Sigmoid(),\n\n            nn.Linear((self.seq+1)*6, (self.seq+1)*6),\n            nn.Dropout(0.5),\n            nn.ReLU(inplace=True),\n\n        )\n        self.conv1 = nn.Sequential(\n            # seq * 5 \n            nn.Conv2d(1, 2, kernel_size=(3,3), padding=2, bias=False), # (seq+2) * 7\n            nn.BatchNorm2d(2),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(2, 2, kernel_size=(3,3), padding=1, bias=False), # (seq+2) * 7\n            nn.BatchNorm2d(2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=(2,2), stride=1), # (seq+1) * 6\n            \n        )\n        \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(1, 2, kernel_size=(2,2), padding=0, bias=False), # seq * 5\n            nn.BatchNorm2d(2),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(2, 1, kernel_size=(1,1), padding=0, bias=True), # seq * 5\n            nn.ReLU(inplace=True)\n\n        )\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = out.view(out.size()[0], -1)\n        out = self.linear(out)\n        # print(out.shape)\n        with torch.no_grad():\n            out = out.reshape(self.batch_size, 1, self.seq+1, 6)\n        out = self.conv2(out)\n        assert out.shape==x.shape, \"Shape Unequal Error.\"\n        return out + x\n    \n    \n\nimport math\nimport numpy as np\nfrom scipy import stats\ndef rsquared(x, y): \n    assert x.shape==y.shape, \"Unequal Shape Error\"\n    r, x, y = [], x.detach(), y.detach()\n    x, y = x.mean(dim=[0,1], keepdim=False), y.mean(dim=[0,1], keepdim=False)\n    for i in range(x.shape[-1]):\n        _, _, r_value, _, _ = stats.linregress(x[:][i].detach().numpy(), y[:][i].detach().numpy()) \n        r.append(r_value ** 2)\n    return r\n","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:21:14.382841Z","iopub.execute_input":"2023-03-19T17:21:14.383272Z","iopub.status.idle":"2023-03-19T17:21:14.409504Z","shell.execute_reply.started":"2023-03-19T17:21:14.383237Z","shell.execute_reply":"2023-03-19T17:21:14.408206Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"excel = pd.read_excel('/kaggle/input/a32-data/A32.xlsx', header=None)\nexcel.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:21:14.412319Z","iopub.execute_input":"2023-03-19T17:21:14.412937Z","iopub.status.idle":"2023-03-19T17:21:15.170911Z","shell.execute_reply.started":"2023-03-19T17:21:14.412896Z","shell.execute_reply":"2023-03-19T17:21:15.169818Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(4459, 18)"},"metadata":{}}]},{"cell_type":"code","source":"sp = [1486, 2972, 4458]\nstation_1 = excel.iloc[1:sp[0]+1,1:6]\nstation_2 = excel.iloc[sp[0]+1:sp[1]+1,1:6]\nstandard = excel.iloc[sp[1]+1:sp[2]+1,1:6]\nstandard.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:21:15.172662Z","iopub.execute_input":"2023-03-19T17:21:15.173076Z","iopub.status.idle":"2023-03-19T17:21:15.182470Z","shell.execute_reply.started":"2023-03-19T17:21:15.173035Z","shell.execute_reply":"2023-03-19T17:21:15.181106Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(1486, 5)"},"metadata":{}}]},{"cell_type":"code","source":"station_1 = df2arr(station_1)\nstation_2 = df2arr(station_2)\nstandard = df2arr(standard)\nstation_1.shape, station_2.shape, standard.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:21:15.186122Z","iopub.execute_input":"2023-03-19T17:21:15.187004Z","iopub.status.idle":"2023-03-19T17:21:15.196718Z","shell.execute_reply.started":"2023-03-19T17:21:15.186963Z","shell.execute_reply":"2023-03-19T17:21:15.195475Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"((1486, 5), (1486, 5), (1486, 5))"},"metadata":{}}]},{"cell_type":"code","source":"s1_minus_sd = station_1 - standard\ns2_minus_sd = station_2 - standard\ns1_div_sd = station_1 / standard\ns2_div_sd = station_2 / standard","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:21:15.198031Z","iopub.execute_input":"2023-03-19T17:21:15.198989Z","iopub.status.idle":"2023-03-19T17:21:15.206344Z","shell.execute_reply.started":"2023-03-19T17:21:15.198943Z","shell.execute_reply":"2023-03-19T17:21:15.205058Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in true_divide\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n  after removing the cwd from sys.path.\n","output_type":"stream"}]},{"cell_type":"code","source":"s1_minus_sd.shape, s2_minus_sd.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:21:15.207911Z","iopub.execute_input":"2023-03-19T17:21:15.208900Z","iopub.status.idle":"2023-03-19T17:21:15.217175Z","shell.execute_reply.started":"2023-03-19T17:21:15.208857Z","shell.execute_reply":"2023-03-19T17:21:15.215884Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"((1486, 5), (1486, 5))"},"metadata":{}}]},{"cell_type":"code","source":"s1_M, s1_m, s1 = ArrNorm(station_1)\ns2_M, s2_m, s2 = ArrNorm(station_2)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:21:15.218742Z","iopub.execute_input":"2023-03-19T17:21:15.219509Z","iopub.status.idle":"2023-03-19T17:21:15.283945Z","shell.execute_reply.started":"2023-03-19T17:21:15.219465Z","shell.execute_reply":"2023-03-19T17:21:15.283009Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def GetDataset(input_arr: list, output_arr: list, seq: int):\n    assert(len(input_arr)==len(output_arr)), \"Different size of input and output!\"\n    Input = []\n    Output = []\n    for i in range(input_arr.shape[0]-seq):\n        Input.append(input_arr[i:i+seq][:])\n        Output.append(output_arr[i:i+seq][:])\n    return torch.tensor(Input, dtype=torch.float32), torch.tensor(Output, dtype=torch.float32)\n\n        \ndef load_array(data_arrays, batch_size, is_train=True):\n    # data-iter\n    dataset = data.TensorDataset(*data_arrays)\n    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n\ns1_minus_sd.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:21:15.285280Z","iopub.execute_input":"2023-03-19T17:21:15.285726Z","iopub.status.idle":"2023-03-19T17:21:15.297279Z","shell.execute_reply.started":"2023-03-19T17:21:15.285690Z","shell.execute_reply":"2023-03-19T17:21:15.296069Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(1486, 5)"},"metadata":{}}]},{"cell_type":"code","source":"# global sequence, batch_size\n# batch_size = 4\n# sequence = 6\n\n# global lr, num_epoch\n# lr, num_epoch = 0.000001, 100\n# status_list = ['MINUS', 'DIVIDE']\nstatus_list = [\"MINUS\"]\nglobal record\nrecord_R = []\nrecord_con = []\n\ndef train(status, batch_size, sequence, lr, num_epoch, ga):\n    string = \"&\"+str(status)+\"&batch_size=\"+str(batch_size)+\"&sequence=\"+str(sequence)+\"&lr=\"+str(lr)+\"&num_epoch\"+str(num_epoch)+\"&gama=\"+str(ga)+\"&\"\n    \n    Input_Data_1, Output_Data_1 = GetDataset(s1, s1_minus_sd, sequence) if status==\"MINUS\" else GetDataset(s1,s1_div_sd, sequence)\n    Input_Data_2, Output_Data_2 = GetDataset(s2, s2_minus_sd, sequence) if status==\"MINUS\" else GetDataset(s2,s2_div_sd, sequence)\n    Input_Data_1.shape, Input_Data_2.shape\n\n    Input_Data_1 = Input_Data_1.unsqueeze(1)\n    Output_Data_1 = Output_Data_1.unsqueeze(1)\n    Input_Data_2 = Input_Data_2.unsqueeze(1)\n    Output_Data_2 = Output_Data_2.unsqueeze(1)\n    Input_Data_1.shape, Input_Data_1.shape\n\n\n    data_tot_1 = torch.utils.data.TensorDataset(Input_Data_1, Output_Data_1)\n    data_tot_2 = torch.utils.data.TensorDataset(Input_Data_2, Output_Data_2)\n    train_size = int(Input_Data_1.shape[0] * cr)\n    test_size = Input_Data_1.shape[0] - train_size\n    train_set_1, test_set_1 = random_split(data_tot_1,[train_size,test_size],\n                                        torch.Generator().manual_seed(0))\n    train_set_2, test_set_2 = random_split(data_tot_2,[train_size,test_size],\n                                        torch.Generator().manual_seed(0))\n    # DataIter = load_array((Input_Data_1, Output_Data_1), batch_size=8)\n\n\n\n\n    Data_Iter_1 = DataLoader(dataset=train_set_1, batch_size=batch_size, shuffle=True, drop_last=True)\n    Data_Iter_2 = DataLoader(dataset=train_set_2, batch_size=batch_size, shuffle=True, drop_last=True)\n\n    for i, dt in enumerate(Data_Iter_1):\n        if dt[0].shape[0]!=batch_size:\n            print(dt[0].shape)\n            print(i, batch_size, dt[0].shape[0], dt)\n\n    for i, dt in enumerate(Data_Iter_2):\n        if dt[0].shape[0]!=batch_size:\n            print(dt[0].shape)\n            print(i, batch_size, dt[0].shape[0], dt)\n\n    x_plt, train_loss_plt = [], []\n\n\n    net = Try(batch_size=batch_size, seq=sequence).cuda()\n    Loss = torch.nn.MSELoss()\n    optimizer = torch.optim.Adam(net.parameters(), lr)\n    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=ga)\n\n    def Iter(num_epoch):\n        cnt = 0\n        while cnt < num_epoch:\n            yield cnt\n            cnt += 1\n\n    print(\"\\nStart Training with condition: \"+string)\n    print(\"Round 1...\")\n    for epoch in range(num_epoch):\n        epoch_start_time = time.time()\n        train_loss = 0.0\n        net.train()\n        for i, use in enumerate(tqdm(Data_Iter_1)):\n            optimizer.zero_grad()\n            # if use[0].shape[0]==2:\n            #     print(use[0])\n            train_pred = net(use[0].cuda())    # use[0].cuda()\n\n            batch_loss = Loss(train_pred, use[1].cuda())   # use[1].cuda()\n            batch_loss.backward()\n            optimizer.step()\n#             R2 = R_square(train_pred.cpu(), use[1].cpu())\n\n            train_loss += batch_loss.item()\n\n        train_loss = train_loss / train_size\n        x_plt.append(epoch+1)\n        train_loss_plt.append(train_loss)\n        print(\"Round-1 --- [%2d|%2d] %.2f(s) Train_Loss=%.6f \"%\\\n                (epoch+1,num_epoch,time.time()-epoch_start_time,train_loss),end='')\n    #   epoch_start_time = time.time()\n        scheduler.step()  \n\n    plt.figure(1)\n    plt.plot(x_plt,train_loss_plt,'rs-',label='all_train_loss')\n    plt.show()\n\n    print(\"Round 2...\")\n    for epoch in range(num_epoch):\n        epoch_start_time = time.time()\n        train_loss = 0.0\n        net.train()\n        for i, use in enumerate(tqdm(Data_Iter_2)):\n            optimizer.zero_grad()\n            # if use[0].shape[0]==2:\n            #     print(use[0])\n            train_pred = net(use[0].cuda())    # use[0].cuda()\n\n            batch_loss = Loss(train_pred, use[1].cuda())   # use[1].cuda()\n            batch_loss.backward()\n            optimizer.step()\n            # R2 = rsquared(train_pred.cpu(), use[1].cpu())\n\n            train_loss += batch_loss.item()\n\n        train_loss = train_loss / train_size\n        x_plt.append(epoch+num_epoch+1)\n        train_loss_plt.append(train_loss)\n        print(\"Round 2 --- [%2d|%2d] %.2f(s) Train_Loss=%.6f \"%\\\n                (epoch+1,num_epoch,time.time()-epoch_start_time,train_loss),end='')\n    #   epoch_start_time = time.time()\n        scheduler.step() \n\n\n    plt.figure(2)\n    plt.plot(x_plt,train_loss_plt,'rs-',label='all_train_loss')\n    plt.show()\n\n    torch.save(net.state_dict(), '/kaggle/working/'+string+\".pt\")\n    print(\"Parameters Saved.\")\n\n\n    Test_Iter_1 = DataLoader(dataset=test_set_1, batch_size=1, shuffle=False, drop_last=True)\n    model = Try(batch_size=1, seq=sequence)\n    model.load_state_dict(torch.load('/kaggle/working/'+string+\".pt\"))\n    model = model.cuda()\n    model.eval()\n    R_list = [[],[],[],[],[]]\n    def app(R: list)-> list:\n        assert len(R)==5\n        for i in range(len(R_list)):\n            R_list[i].append(R[i])\n\n    with torch.no_grad():\n        for i, use in enumerate(Test_Iter_1):\n            pred = model(use[0].cuda())\n            R = rsquared(pred.cpu(), use[1])\n            print(i, R)\n            for i in range(5):\n                R_list[0].append(R)\n                           \n                           \n    Test_Iter_2 = DataLoader(dataset=test_set_2, batch_size=1, shuffle=False, drop_last=True)\n\n    with torch.no_grad():\n        for i, use in enumerate(Test_Iter_2):\n            pred = model(use[0].cuda())\n    #         print(pred.shape, use[1].shape)\n            R = rsquared(pred.cpu(), use[1])\n            print(i, R)\n            for i in range(5):\n                R_list[0].append(R)\n    \n    record_R.append(R_list)\n    record_con.append(string)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:21:15.298968Z","iopub.execute_input":"2023-03-19T17:21:15.299487Z","iopub.status.idle":"2023-03-19T17:21:15.327112Z","shell.execute_reply.started":"2023-03-19T17:21:15.299450Z","shell.execute_reply":"2023-03-19T17:21:15.326097Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# train('MINUS',10,6,0.0001,5,0.9)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:21:15.332178Z","iopub.execute_input":"2023-03-19T17:21:15.332731Z","iopub.status.idle":"2023-03-19T17:21:15.339887Z","shell.execute_reply.started":"2023-03-19T17:21:15.332704Z","shell.execute_reply":"2023-03-19T17:21:15.338834Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# record_R, record_con","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:21:15.341444Z","iopub.execute_input":"2023-03-19T17:21:15.341847Z","iopub.status.idle":"2023-03-19T17:21:15.348705Z","shell.execute_reply.started":"2023-03-19T17:21:15.341795Z","shell.execute_reply":"2023-03-19T17:21:15.347492Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"for status in status_list:\n    for num_epoch in [1000,1500,2000]:\n        for ga in [0.80,0.85,0.90]:\n            for batch_size in [2,4,8,16,32,64]:\n                for lr in [0.00001,0.0001,0.0001,0.001,0.03]:\n                    for sequence in [4,5,6,7,8,9,10]:\n                        train(status, batch_size, sequence, lr, num_epoch, ga)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T17:21:15.350593Z","iopub.execute_input":"2023-03-19T17:21:15.351004Z","iopub.status.idle":"2023-03-19T17:21:27.014465Z","shell.execute_reply.started":"2023-03-19T17:21:15.350968Z","shell.execute_reply":"2023-03-19T17:21:27.012728Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"\nStart Training with condition: &MINUS&batch_size=2&sequence=4&lr=1e-05&num_epoch500&gama=0.8&\nRound 1...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 711/711 [00:02<00:00, 298.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Round-1 --- [ 1|500] 2.39(s) Train_Loss=111.330980 ","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 711/711 [00:01<00:00, 385.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Round-1 --- [ 2|500] 1.85(s) Train_Loss=111.336677 ","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 711/711 [00:02<00:00, 344.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Round-1 --- [ 3|500] 2.07(s) Train_Loss=111.330530 ","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 711/711 [00:01<00:00, 375.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Round-1 --- [ 4|500] 1.90(s) Train_Loss=111.322812 ","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 711/711 [00:01<00:00, 373.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Round-1 --- [ 5|500] 1.91(s) Train_Loss=111.319810 ","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 519/711 [00:01<00:00, 374.34it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/1372506031.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.03\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mga\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_24/1948335442.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(status, batch_size, sequence, lr, num_epoch, ga)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# use[1].cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;31m#             R2 = R_square(train_pred.cpu(), use[1].cpu())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    250\u001b[0m                  \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fused'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                  \u001b[0mgrad_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                  found_inf=found_inf)\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    314\u001b[0m          \u001b[0mdifferentiable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdifferentiable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m          \u001b[0mgrad_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m          found_inf=found_inf)\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}